{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "What is Data Augmentation?\n",
    "\n",
    "Data Augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified data from the existing one.\n",
    "\n",
    "It is a good technique if you want to prevent overfitting, or the initial dataset is too small to train on, or even if you want to squeeze better performance from your model.\n",
    "\n",
    "## Data Augmentation techniques\n",
    "* Geometric transformations: Randomly flip, crop, rotate or translate images.\n",
    "* Color space transformations: change RGB color channels, intensify any color.\n",
    "* Kernel filters: sharpen or blur an image.\n",
    "* Random Erasing: delete a part of the initial image.\n",
    "* Mixing images: basically, mix images with one another.\n",
    "## Data Augmentation Frameworks:\n",
    "* TensorFlow\n",
    "* Keras\n",
    "* PyTorch\n",
    "\n",
    "Sources:\n",
    "* https://neptune.ai/blog/data-augmentation-in-python\n",
    "* https://pytorch.org/tutorials/beginner/data_loading_tutorial.html?highlight=dataloader\n",
    "* https://towardsdatascience.com/a-comprehensive-guide-to-image-augmentation-using-pytorch-fb162f2444be"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.8.2+cu102)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.9.2+cu102)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.20.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (9.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data and images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_faces.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                        filename  age  gender  ethnicity\n0  100_1_0_20170110183726390.jpg  100       1          0\n1  100_1_2_20170105174847679.jpg  100       1          2\n2  100_1_2_20170110182836729.jpg  100       1          2\n3  101_1_2_20170105174739309.jpg  101       1          2\n4   10_0_0_20161220222308131.jpg   10       0          0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>ethnicity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100_1_0_20170110183726390.jpg</td>\n      <td>100</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100_1_2_20170105174847679.jpg</td>\n      <td>100</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100_1_2_20170110182836729.jpg</td>\n      <td>100</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>101_1_2_20170105174739309.jpg</td>\n      <td>101</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10_0_0_20161220222308131.jpg</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get pictures as numpy arrays"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-5266dbd6d36b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mpath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'pic/'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mimage\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m     \u001B[0mimages_as_arrays\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36m__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m    717\u001B[0m             \u001B[0mnew\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"data\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtobytes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"raw\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"L\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    718\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 719\u001B[1;33m             \u001B[0mnew\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"data\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtobytes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    720\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    721\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_ArrayData\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mtobytes\u001B[1;34m(self, encoder_name, *args)\u001B[0m\n\u001B[0;32m    760\u001B[0m             \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    761\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 762\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    763\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    764\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwidth\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mheight\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\vio_g\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\PIL\\ImageFile.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    256\u001B[0m                             \u001B[0mb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mb\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 257\u001B[1;33m                             \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merr_code\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdecoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    258\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    259\u001B[0m                                 \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "images_as_arrays = []\n",
    "\n",
    "for idx, image in enumerate(df['filename']):\n",
    "    path = 'pic/' + image\n",
    "    img = Image.open(path)\n",
    "    img = np.array(img)\n",
    "    images_as_arrays.append(img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[231 234 241]\n",
      "  [234 237 244]\n",
      "  [233 236 243]\n",
      "  ...\n",
      "  [220 225 229]\n",
      "  [223 227 230]\n",
      "  [223 227 230]]\n",
      "\n",
      " [[222 225 232]\n",
      "  [226 229 236]\n",
      "  [231 234 241]\n",
      "  ...\n",
      "  [224 229 233]\n",
      "  [228 232 235]\n",
      "  [228 232 235]]\n",
      "\n",
      " [[222 225 232]\n",
      "  [221 224 231]\n",
      "  [226 229 236]\n",
      "  ...\n",
      "  [226 231 235]\n",
      "  [214 217 222]\n",
      "  [213 216 221]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "print(images_as_arrays[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Augmentation in Keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Augmentation in PyTorch\n",
    "\n",
    "PyTorch contains the transforms library for data augmentation.\n",
    "\n",
    "Transform library contains different image transformations that can be chained together using the compose method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resize\n",
    "\n",
    "One issue we can face is that the samples are not of the same size. Most neural networks expect the images of fixed size.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Investigate size of the first 5 pictures:\n",
    "\n",
    "for idx, image_array in images_as_arrays[0:5]:\n",
    "    print(f\"Image {idx} has shape {image_array.size}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resized_images = []\n",
    "size = (128, 128)\n",
    "for img in images_as_arrays:\n",
    "    resized_img = T.Resize(size=size) (img)\n",
    "    resized_images.append(resized_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for idx, image_array in images_as_arrays[0:5]:\n",
    "    print(f\"Image {idx} has shape {image_array.size}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(resized_images[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
